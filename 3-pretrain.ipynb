{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d42342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,time,math,pickle,random,shutil\n",
    "import numpy as np,pandas as pd\n",
    "import torch,torch._dynamo\n",
    "from model import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb047db",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19b952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"long\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ad3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1337\n",
    "out_dir = 'long'\n",
    "if resume: \n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "else:\n",
    "    shutil.rmtree(out_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b6810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=open(os.path.join(data_dir, 'train.bin'), 'r')\n",
    "evrythng=fp.readlines()\n",
    "train_names=[]\n",
    "for line in evrythng:\n",
    "    train_names.append(line.split(\"\\n\")[0])\n",
    "fp.close()\n",
    "fp=open(os.path.join(data_dir, 'val.bin'), 'r')\n",
    "evrythng=fp.readlines()\n",
    "val_names=[]\n",
    "for line in evrythng:\n",
    "    val_names.append(line.split(\"\\n\")[0])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a7a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos, vocab_size = meta['stoi'], meta['itos'], meta['vocab_size']\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad53266",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "block_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b086a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 6\n",
    "n_head = 6\n",
    "n_embd = 216\n",
    "dropout = 0.2\n",
    "bias=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca5516da",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "max_iters = 200000\n",
    "lr_decay_iters = 200000\n",
    "min_lr = 1e-4\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.99\n",
    "warmup_iters = 1000\n",
    "grad_clip = 1.0\n",
    "decay_lr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74df2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_interval = 500\n",
    "log_interval = 100\n",
    "eval_iters = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e473602",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "#torch._dynamo.config.suppress_errors = True\n",
    "dtype='float16'\n",
    "compile=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36887b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens per iteration will be: 3,200\n"
     ]
    }
   ],
   "source": [
    "tokens_per_iter =  batch_size * block_size\n",
    "print(f\"tokens per iteration will be: {tokens_per_iter:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "401658cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11a9dd3d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "556780d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_names if split == 'train' else val_names\n",
    "    ix = torch.randint(len(data), (batch_size,))\n",
    "    pad_token=stoi[\"*\"]\n",
    "    x=torch.ones(batch_size,block_size,dtype=torch.long)*pad_token\n",
    "    y=torch.ones(batch_size,block_size,dtype=torch.long)*pad_token\n",
    "    for i,index in enumerate(ix):\n",
    "        encoded=encode(data[index])\n",
    "        x[i][:len(encoded)-1]=torch.Tensor(encoded[:-1])\n",
    "        y[i][:len(encoded)-1]=torch.Tensor(encoded[1:])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2376b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size, bias=bias,\n",
    "            vocab_size=vocab_size, dropout=dropout, pad_token=stoi[\"*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "100f8f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3.37M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(55, 216, padding_idx=27)\n",
       "    (wpe): Embedding(50, 216)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=216, out_features=648, bias=False)\n",
       "          (c_proj): Linear(in_features=216, out_features=216, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=216, out_features=864, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=864, out_features=216, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=216, out_features=55, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if resume:\n",
    "    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    config = checkpoint['config']\n",
    "    model = GPT(config)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "    iter_num = checkpoint['iter_num']\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "else:\n",
    "    model=GPT(config)\n",
    "model.to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "644f16f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 26, with 3,381,912 parameters\n",
      "num non-decayed parameter tensors: 13, with 2,808 parameters\n"
     ]
    }
   ],
   "source": [
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2))\n",
    "if resume:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44287bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compile:\n",
    "    print(\"compiling the model... (takes a ~minute)\")\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df8ac3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return min_lr + coeff * (learning_rate - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de00bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 148500: train loss 1.9064, val loss 2.0106\n",
      "iter 148500: loss 2.0001, time 18284.98ms\n",
      "iter 148600: loss 1.9281, time 189.75ms\n",
      "iter 148700: loss 1.9201, time 194.36ms\n",
      "iter 148800: loss 1.9718, time 193.77ms\n",
      "iter 148900: loss 2.0280, time 186.52ms\n",
      "step 149000: train loss 1.9030, val loss 2.0224\n",
      "iter 149000: loss 1.9999, time 17632.54ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# clip the gradient\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad_clip \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#scaler.unscale_(optimizer)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#scaler.step(optimizer)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#scaler.update()\u001b[39;00m\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/Applications/miniforge3/envs/tf/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:59\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m             norms\u001b[38;5;241m.\u001b[39mextend([torch\u001b[38;5;241m.\u001b[39mnorm(g, norm_type) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads])\n\u001b[1;32m     61\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(torch\u001b[38;5;241m.\u001b[39mstack([norm\u001b[38;5;241m.\u001b[39mto(first_device) \u001b[38;5;28;01mfor\u001b[39;00m norm \u001b[38;5;129;01min\u001b[39;00m norms]), norm_type)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n",
      "File \u001b[0;32m/Applications/miniforge3/envs/tf/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m             norms\u001b[38;5;241m.\u001b[39mextend([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads])\n\u001b[1;32m     61\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(torch\u001b[38;5;241m.\u001b[39mstack([norm\u001b[38;5;241m.\u001b[39mto(first_device) \u001b[38;5;28;01mfor\u001b[39;00m norm \u001b[38;5;129;01min\u001b[39;00m norms]), norm_type)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n",
      "File \u001b[0;32m/Applications/miniforge3/envs/tf/lib/python3.10/site-packages/torch/functional.py:1530\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1529\u001b[0m         _dim \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)]  \u001b[38;5;66;03m# noqa: C416 TODO: rewrite as list(range(m))\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdim\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;66;03m# remove the overloads where dim is an int and replace with BraodcastingList1\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;66;03m# and remove next four lines, replace _dim with dim\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
    "X, Y = get_batch('train') # fetch the very first batch\n",
    "t0 = time.time()\n",
    "if not resume:\n",
    "    iter_num = 0\n",
    "    best_val_loss = 1e9\n",
    "while True:\n",
    "\n",
    "    # determine and set the learning rate for this iteration\n",
    "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    # evaluate the loss on train/val sets and write checkpoints\n",
    "    if iter_num % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            if iter_num > 0:\n",
    "                checkpoint = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'iter_num': iter_num,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                    'config': config,\n",
    "                }\n",
    "                print(f\"saving checkpoint to {'temp'}\")\n",
    "                torch.save(checkpoint, os.path.join(\"temp\", 'ckpt.pt'))\n",
    "\n",
    "    logits, loss = model(X, Y)\n",
    "    X, Y = get_batch('train')\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    #scaler.scale(loss).backward()\n",
    "    loss.backward()\n",
    "    # clip the gradient\n",
    "    if grad_clip != 0.0:\n",
    "        #scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    # timing and logging\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0\n",
    "    t0 = t1\n",
    "    if iter_num % log_interval == 0:\n",
    "        lossf = loss.item()\n",
    "        print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms\")\n",
    "    iter_num += 1\n",
    "\n",
    "    # termination conditions\n",
    "    if iter_num > max_iters:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c835f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
