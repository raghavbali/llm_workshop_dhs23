Module 1.1 Introduction to Generative AI: In this module, participants will gain a comprehensive understanding of Generative AI, a subfield of artificial intelligence focused on creating models that generate data, such as images, texts, or audio. The module will delve into the fundamental concepts of generative models, including their applications in various domains like creative content generation, data augmentation, and anomaly detection. Participants will also explore popular generative models such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), and learn how these models have changed the AI landscape.
Module 1.2 The NLP Journey (TF-IDF to Word2Vec to Sequence Modeling to Transformers): This segment of Module 1 takes participants on a journey through the evolution of Natural Language Processing (NLP) techniques. It starts with the basics of TF-IDF (Term Frequency-Inverse Document Frequency) and its significance in text representation. Next, participants will explore the advancements made with Word2Vec and how word embeddings have revolutionized NLP tasks by capturing semantic relationships between words. The workshop will then progress to sequence modeling, where participants will understand how recurrent neural networks (RNNs) and Long Short-Term Memory (LSTM) networks are used for sequential data processing. Finally, the module concludes by introducing participants to the state-of-the-art Transformers, like BERT and GPT, which have achieved groundbreaking results in various NLP tasks, including language translation, sentiment analysis, and question-answering.
Module 2.1 Language Modeling using Seq2Seq Models: In this module, participants will dive into language modeling techniques, with a focus on Sequence-to-Sequence (Seq2Seq) models. They will learn how these models are designed to process sequential data, such as natural language sentences, and how they have been widely adopted for tasks like machine translation, text summarization, and dialogue generation. This module will guide participants through the architecture and training process of Seq2Seq models, helping them develop a solid understanding of their applications and limitations.
Module 3.1: The Awakening of GPT-3 and LLMs:Participants will delve into the fascinating journey of GPT-3 (Generative Pre-trained Transformer 3) and other Large Language Models (LLMs). This module provides a historical context for the emergence of GPT-3 and explores the advancements that led to the development of these powerful language models. Attendees will gain insights into the revolutionary impact of LLMs on various AI applications and understand the underlying innovations that have propelled the field of natural language generation.
Module 3.2: Understanding ChatGPT:This part of Module 3 focuses on comprehending ChatGPT, a specific application of language models for interactive conversational agents. Participants will explore key techniques employed in ChatGPT's development, such as Instruction Tuning using InstructGPT and ControlNet for guided responses. They will also learn about SFT (System Focused Training) and RLHF (Reinforcement Learning from Human Feedback) approaches, which enhance the performance and safety of ChatGPT, making it more useful and reliable for real-world applications.
Module 3.3: Fine Tuning LLMs (PEFT techniques: Prefix-tuning, LoRa, QLoRa, etc.):In this segment, participants will gain expertise in fine-tuning Large Language Models (LLMs) to suit specific tasks using advanced techniques like Prefix-tuning, LoRa, QLoRa, and more. They will learn how to adapt LLMs to specialized domains and improve their performance on targeted tasks through these innovative pre-training and fine-tuning (PEFT) methods. Practical examples and hands-on exercises will empower participants to fine-tune LLMs effectively.
Module 3.4: Evaluation of LLMs/Benchmarks:Participants will discover how to evaluate the performance and quality of Large Language Models (LLMs) and understand the significance of benchmarks in this process. This module will introduce various evaluation metrics and methodologies to assess LLMs objectively, enabling participants to gauge their strengths and limitations accurately.
Module 3.5: Limitations of LLMs:This part of the workshop highlights the inherent limitations of Large Language Models (LLMs) and explores challenges associated with their deployment. Participants will gain a nuanced understanding of issues like biased outputs, lack of common sense reasoning, and sensitivity to input phrasing. Moreover, the workshop will address ethical concerns and considerations related to using LLMs responsibly.